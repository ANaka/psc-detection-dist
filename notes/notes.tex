%template complements of http://www.arcadianvisions.com/blog/?p=115
\documentclass{article}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{graphicx}
\usepackage[round]{natbib}
\usepackage{float}
\usepackage{enumerate}
\usepackage[left=1in, top=1in, right=01in, bottom=1in]{geometry}
%\begin{lstlisting}
%\end{lstlisting}
\usepackage{caption}
\usepackage{subfig}
\usepackage{hyperref}
\usepackage{bbm}
\usepackage{datetime}

\usepackage{tikz}
\usetikzlibrary{shapes,shadows}
\tikzstyle{abstractbox} = [draw=black, fill=white, rectangle, 
inner sep=10pt, style=rounded corners, drop shadow={fill=black,
opacity=1}]
\tikzstyle{abstracttitle} =[fill=white]
  
\newcommand{\boxabstract}[2][fill=white]{
    \begin{center}
      \begin{tikzpicture}
        \node [abstractbox, #1] (box)
        {\begin{minipage}{0.80\linewidth}
%            \setlength{\parindent}{2mm}
            \footnotesize #2
          \end{minipage}};
        \node[abstracttitle, right=10pt] at (box.north west) {Note};
      \end{tikzpicture}
    \end{center}
  }
    
\newcommand{\mat}[1]{\begin{bmatrix}#1\end{bmatrix}}

\title{Bayesian PSC detection} 
\author{Josh Merel, Ben Shababo, Liam Paninski} 

\begin{document}

\maketitle

%\begin{flushright}
%\end{flushright}

%\begin{center}
%\section*{}
%\end{center}

\section*{Overview}
When recording from patched cells, it is possible to measure current flows using a voltage clamp system which is designed to hold the voltage at a fixed value.  In this setting transient current flows register as brief deviations of the recorded current level away from a baseline value. In certain settings, the noise may also include some structured temporal autocorrelation, especially when the system is \textit{in vivo} as the voltage clamp system is not perfectly able to maintain the baseline value.

There are already existing methods for detecting post-synaptic currents (PSCs), but we find that a straightforward Bayesian approach based on sampling the parameters of a simple, generative model of the PSC process works better than the existing approaches we have tried. 

\boxabstract{More thorough set of comparisons will be considered.  Include discussion of \cite{pernia2012deconvolution} and \cite{richardson2008measurement}}

Existing algorithms of which we are aware include propriety software (e.g. minianalysis) and \textit{ad hoc} approaches to event detection that tend to rely on simple heuristics for what constitutes an event (e.g. a deviation above a certain threshold). However, such heuristics produce all-or-none results and the precise timing of the event is a secondary consideration.  Using a Bayesian approach, it is straightforward to consider posterior uncertainty -- we essentially get a level of condfidence for each event and the level of uncertainty in the precise timing of the event.  In this sense, even if a Bayesian method were only comparable to a more \textit{ad hoc} approach, there may still be advantages depending on whether posterior uncertainty were desired.  As additional baselines, expert humans often detect PSCs by hand (a slow process that insists upon automation for large scale recording) so we compare against this as a sort of ground truth.   

The method described next is largely a domain-specific application of tools developed in statistics \cite{moller2004} and signal processing \cite{tan2008}.  In previous work, we have found methods of this sort useful for calcium imaging data analysis \cite{pnevmatikakis2013bayesian}.  Details for the AR($p$) noise model come from \cite{chib1994bayes}.  The basic framework involves (1) specifying the model which generates the traces from the events (in terms of event times and model parameters) and (2) performing Bayesian inference on event times and model parameters jointly.  Theoretically, such an approach has nice guarantees.  However, this approach can fail if the model is inadequate (i.e. the model relating events to traces is not realistic) or if the inference algorithm performs poorly and the true model posterior is not obtained.  While these concerns are legitimate in the abstract, in practice, this method performs well and there is tremendous utility of an interpretable model with the flexibility in parameter estimation that this approach permits.   

   
\section*{Problem formalization} 

Suppose we observe a timeseries $Y$, with the value at each time given by $y_t$.  This timeseries may be modeled as an autoregressive process if it is the result of some physical system.  In general, various kinds of noise are able to be handled -- for our purposes here we model the noise additive noise applied to the observations.  The noise process can also be autoregressive.  As a specific, but quite flexible model form, we consider the following equation:

\begin{align}
y_{t} &= \sum_{i=1}^n a_{i} k_i(t-t_{i}) + b + \epsilon_t \\
\epsilon_t &= \sum_{j=1}^p \phi_j \epsilon_{t-j} + u_t \hspace*{.5in} u_t \sim \mathcal{N}(0,\sigma^2) \label{AR_noise}
\end{align}

This equation asserts that the trace is composed of a sum of responses to individual events and that each event has a response profile determined by $k_i(\cdot)$.  The trace contains $n$ events at times $\{t_i\}$, each with magnitude $a_{i}$.  $b$ is the baseline value. $\epsilon_t$ is noise from an AR($p$) noise process. $k_i(\cdot)$ is parameterized by two time constants and is of a sum-of-exponentials form, $(e^{-t/\tau_f^{(i)}} - e^{-t/\tau_r^{(i)}})\mathbbm{1}(t>=0)$, with $\tau_f^{(i)}$ and $\tau_r^{(i)}$ the time constants for fall and rise respectively for the $i^{th}$ event.

We can also interpret this probabilistically.  We begin with the i.i.d (i.e. AR($0$)) case:
\begin{equation}
p(Y|\Theta) = \prod_{t=1}^T (2\pi\sigma^2)^{-1/2} exp[-\frac{1}{2\sigma^2}(y_t - \hat y_t)^2]
\end{equation}

In the above equation, $\Theta$ is the set of all parameters $\{\sigma,a_i,t_i,\tau_f^{(i)}, \tau_r^{(i)},b \}$, and we use $\hat y_t$ to refer to the predicted noiseless trace:
\begin{equation}
\hat y_t = \sum_{i=1}^n a_{i} k_i(t-t_{i}) + b
\end{equation} 

It is pointed out in equation 8 of \cite{chib1994bayes} that with the AR($p$) noise model, the probability distribution is:
\begin{equation}
\label{main_likelihood}
p(Y|\Theta) = \prod_{t=1}^T (2\pi\sigma^2)^{-1/2} exp[-\frac{1}{2\sigma^2}(y_t - \hat y_{t|t-1})^2]
\end{equation}

Where $\hat y_{t|t-1}$ is (adapted from equation 11 of \cite{chib1994bayes}, ignoring boundary conditions):
\begin{equation}
\hat y_{t|t-1} = \hat y_t + \sum_{j=1}^p \phi_j (y_{t-j} - \hat y_{t-j})
\end{equation} 

In our implementation, we will rely on a $ln(p(Y|\Theta))$ for which we carry around a $T$ vector of $\hat e_t = y_t - \hat y_t$ and we perform evaluations of $y_t - \hat y_{t|t-1}$ by observing that:
\begin{align}
y_t - \hat y_{t|t-1} &= y_t - (\hat y_t + \sum_{j=1}^p \phi_j (y_{t-j} - \hat y_{t-j})) \\
&= y_t - \hat y_t - \sum_{j=1}^p \phi_j (y_{t-j} - \hat y_{t-j})
\end{align}
Where the last line only depends on the stored $\hat e_t$ quantities.

The updates for the $\phi_{1..p}$ and $\sigma$ are provided in section 4.1 of \cite{chib1994bayes}. The update for $\phi_{1..p}$ ends up being conditionally normal with a mean and posterior that depend on $\hat e_t$ and $\sigma$, but also with the constraint that the roots AR($p$) process implied by $\phi_{1..p}$ is stable.  Ignoring boundary conditions:
\begin{align}
E &= [\hat e_{t-1} ... \hat e_{t-p}] \\
\Phi_n &= \Phi_0 + \sigma^{-2}(E'E) \\
\hat \phi &= \Phi_n^{-1} (\Phi_0 \phi_0 + \sigma^{-2} E'e) \\
\phi &\sim \mathcal{N}(\hat \phi,\Phi_n^{-1})\mathbbm{1}_{S \phi}
\end{align}
Where $\mathbbm{1}_{S \phi}$ is an indicator over the set of stable $\phi$ values and $\phi_0$ and $\Phi_0$ are set to weak prior values.
So rejection sampling from the conditional distribution such that the roots are stable is performed.  
$\sigma^2$ can be sampled from an inverse-gamma distribution that is conjugate prior to equation \ref{main_likelihood}.
\begin{align}
\delta_1 &= \sum_{t=1}^T (y_t - \hat y_{t|t-1})^2 \\
\sigma^2 &\sim \mathcal{IG}(0.5 (T + \nu_0),1/(0.5 (\delta_1 + \delta_0)));
\end{align}
Where $\nu_0$ and $\delta_0$ are set to weak prior values.

\section*{Inference}

We perform the inference using MCMC on the probabilistic model.  Essentially we use Gibbs sweep over the parameters and some of the Gibbs steps are sampled by random-walk Metropolis or Metropolis-Hastings (RWMH).

\begin{enumerate}
\item Sample $\{t_i\}$ -- individually by RWMH
\item Sample $\{a_i\}$ -- individually by RWMH
\item Sample $b$ -- by RWMH
\item Sample number of events -- add \& drop events
\item Sample $\{\tau_f^{(i)}, \tau_r^{(i)}\}$ -- individually by RWMH
\item Sample $\phi_{1..p}$ -- rejection sampling from constrained conditional distribution
\item Sample $\sigma$ -- from conditional distribution
\end{enumerate}



\section*{simulation results}

To validate the quality of the event detection algorithm, we can produce simulated traces and run the event detection on these simulated traces.  The simulation pipeline and representative results for intermediate-level noise is depicted in figure \ref{fig:sim_traces}. We have simulated traces with random event times and added various levels of AR(2) noise to the traces (for plausible values of $\phi_{1..p}$ and $\{\tau_f^{(i)},\tau_r^{(i)}\}$). Noise is parameterized for the AR(2) process by $\sigma$ (equation \ref{AR_noise}) which has been varied by an order of magnitude to range from very high SNR to very low SNR.  

Inference is quite similar when there is low levels of noise or the noise is only weakly AR, but the inference results diverge dramatically when the noise is larger in magnitude or the noise process is strongly AR.  Essentially, the AR(2) noise model heavily buffers the inference against false positives due to random structured deviations from baseline.

\begin{figure}[H]
\begin{center}
  \subfloat{\includegraphics[width=1\textwidth]{comparison2_random_snr_5.eps}}  
  \end{center}    
  \captionsetup{width=.7\textwidth}
\captionsetup{font={footnotesize}}
\caption{Representative performance of algorithms at intermediate levels of noise.  Top panel is a clean trace of simulated events.  Second panel is a sample from an AR($2$) noise process.  Third panel is the simulated trace (sum of the top two panels). Fourth panel is inference using the AR($2$) noise model (black is ``observed" trace is in third panel, red are sample traces from the posterior, green is the posterior mean, and dots at top of panel are true event onsets). Fifth panel is a similar depiction for inference performed using the AR($0$) model.  While both models are similar in certain respects, inferred noise levels, posterior uncertainty, and confidence in false positives differ -- the AR($0$) model overfits and estimates more confidently because it estimates lower marginal noise, essentially unable to ignore structured noise deviations and confidently asserting the noise fluctuations to be events.  Bottom panel depicts samples from the joint posterior distribution of amplitude and time of events inferred using the AR($2$) model (with black dots indicating true events.}
\label{fig:sim_traces}
\end{figure}

To summarize the performance of the two inference variants over a range of noise levels, we consider the accuracy of the inferred trace (correlation coefficient between true trace and estimate of posterior mean) as a function of noise level for each algorithm (figure \ref{fig:sim_summary}).  Naturally, we expect the AR($2$) model to perform better insofar as the noise is actually drawn from an AR($2$) noise process.  However, we wish to get a sense of how differently the algorithms perform.  It is not possible to simulate performance differences over all parameter variations, so we have made our comparisons for AR process parameters and time constants held fixed at reasonable values.  These choices are representative of the effects for other reasonable values.  Results are also similar if events are naturalistic in their distribution of amplitudes and time constants and if events occur periodically with no overlap.

\begin{figure}[H]
\begin{center}
  \subfloat{\includegraphics[width=.5\textwidth]{cc_comparison_random.eps}}  
  \end{center}    
  \captionsetup{width=.7\textwidth}
\captionsetup{font={footnotesize}}
\caption{The figure depicts accuracy of inference as a function of noise level for both algorithms -- comparison setting is same as depicted in panels 4 and 5 of fig \ref{fig:sim_traces}, using more events than depicted in those plots.  Accuracy (y-axis) is measured as correlation coefficient between true trace and estimate of posterior mean.  Noise level (x-axis) is varied over an order of magnitude with 1 indicating low noise relative to size of events and 10 indicating noise that is has marginal variance almost as large as the signal.  Both algorithms do very well in the high SNR regime.  As soon as noise level begins to make inference difficult, both algorithms begin to lose accuracy.  However the AR($2$) model inference degrades more slowly. }
\label{fig:sim_summary}
\end{figure}
  
We note that in high SNR regimes, our method requires running the sampler longer or reasonable initialization because mixing and burn-in can behave slightly less predictably with very low noise levels.  This regime is not a particularly interesting regime for the purposes of algorithm assesment because template matching algorithms, greedy optimization, or other direct optimization of the model likelihood can perform well in high SNR regimes and so sample-based inference is excessive.    

\section*{Algorithmic details}

\subsection*{Initialization}

Ben's initialization or run longer from cold start.

\subsection*{Priors and hierarchical structure}

In addition, this framework naturally permits prior distributions for any of the variables in the set $\Theta$ to be specified.  For example, model parameters may be expected to have a certain support (e.g. positive number near some mean value).  It is straightforward to build a prior distribution which appropriately captures this information and it will influence the inferred estimates.  It is also worth explicitly keeping in mind that the posterior distribution for a given parameter only can have support where its prior distribution has support, so hard constraints can be naturally incorporated as prior information.

More sophisticated prior structure can be incorporated by making the model hierarchical.  In our setting we might expect the events to cluster by pre-synaptic cell identity or cell type, it is possible to specify this structure with a hierarchical module in the model and inference will proceed in a way which takes advantage of this.  

%\nocite{*}
\bibliographystyle{plainnat}
{\bibliography{references.bib}}



\end{document}
